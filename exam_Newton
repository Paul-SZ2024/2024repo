%this code is created by ChatGPT, with necessary revisions. 

clc
clear all

% define the objective function:
f = @(x1,x2) 3*x1.^2 + x2.^4;

% plot objective function contours for visualization:
figure(1); clf; fsurf(f,[-3 3 -3 3])
% figure(1); clf; ezcontour(f,[-5 5 -5 5]); axis equal; hold on
figure(2); clf; fcontour(f,[-3 3 -3 3],'MeshDensity',50,'LevelStep',1); axis equal; hold on; grid on

% Define the objective function
%f = @(x) x(1)^2 + 2*x(1)*x(2) + x(2)^2;
f = @(x) 3*x(1)^2 + x(2)^4;

% Define the gradient of the objective function
%df = @(x) [2*x(1)+2*x(2); 2*x(2)+2*x(1)];
df = @(x) [6*x(1); 4*x(2)^3];

% Define the Hessian matrix of the objective function
ddf = @(x) [6, 0; 0, 12*x(2)^2];

% Set the initial guess
x0 = [2; 3];

% Set the maximum number of iterations
maxIterations = 100;

% Set the tolerance for convergence
tolerance = 1e-6;

% Initialize the iteration counter
iteration = 0;

% Perform Newton's method
while iteration < maxIterations
    % Calculate the Newton update
    delta_x = -ddf(x0) \ df(x0);
    
    % Update the estimate of the minimum
    x1 = x0 + delta_x;
    
    % plot current point
    plot([x0(1) x1(1)],[x0(2) x1(2)],'ko-')
    refresh

    % Check for convergence
    if norm(x1 - x0) < tolerance
        break;
    end
    
    % Update the iteration counter and the estimate of the minimum
    iteration = iteration + 1;
    x0 = x1;
end

% Print the result
fprintf('Minimum found at x = [%.4f, %.4f]\n', x1(1), x1(2));
fprintf('Number of iterations: %d\n', iteration);
